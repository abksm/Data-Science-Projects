{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d77ea543-e3e2-4f1f-93ac-aeaaf7cb47fe",
   "metadata": {},
   "source": [
    "# ASL, or American Sign Language\n",
    "Many deaf people in North America communicate primarily through American Sign Language (ASL), which is also widely used by hard-of-hearing and hearing people.<br>\n",
    "The development of computer vision systems that translate sign language to spoken language has advanced significantly in recent years. Complex neural network topologies that are capable of identifying minute patterns in streaming video are frequently the basis for this technology. We can lessen the scope of the issue though by translating individual letters rather than entire sentences in order to gain an idea of how to construct a translation system.<br>\n",
    "In this notebook, we will train a convolutional neural network to identify pictures of letters in ASL. We will train and evaluate the network after loading, preparing and analyzing the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85255278-d442-4d3c-947b-296cb6a25fca",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "The training and test data are loaded into the code cell below.<br>\n",
    "x_train and x_test are arrays of image data with shape (num_samples, 3, 50, 50), respectively.<br>\n",
    "y_train and y_test are arrays of category labels with shape (num_samples,), respectively.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1217419-6194-4660-ae7d-f4916ea298f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(5) \n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(2)\n",
    "from datasets import sign_language\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = sign_language.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4328ad29-7423-4144-b17a-d147a0b34dd1",
   "metadata": {},
   "source": [
    "## Visualizing the training data\n",
    "To start, we will create a list of labels containing the letters appearing in the dataset, then we visualize the first entries in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f263d80-06ca-4b9b-8a6a-ea59222761f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=['A','B','C']\n",
    "fig=plt.figure(figsize=(20,5))\n",
    "for i in range(36):\n",
    "    ax=fig.add_subplot(3,12,i+1,xticks=[],yticks=[])\n",
    "    ax.imshow(np.squeeze(x_train[i]))\n",
    "    ax.set_title(\"{}\".format(labels[y_train[i]]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b09f16b-ce0d-40d9-88b5-f7f605629f3c",
   "metadata": {},
   "source": [
    "## Verifying the dataset integrity\n",
    "\n",
    "The datasets x_train and x_test contain the images, while y_train and y_test contain the corresponding letters.<br>\n",
    "The values for each element in y_train and y_test are 0, 1, or 2, which stand for the letters \"A,\" \"B,\" and \"C,\" respectively.<br>\n",
    "To confirm that the training and test sets contain approximately equal amounts of each letter, we will use the arrays y_train and y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53891a9c-c855-4341-90a5-01e41f4ac4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_A_train = sum(y_train==0)\n",
    "num_B_train = sum(y_train==1)\n",
    "num_C_train = sum(y_train==2)\n",
    "num_A_test = sum(y_test==0)\n",
    "num_B_test = sum(y_test==1)\n",
    "num_C_test = sum(y_test==2)\n",
    "print(\"Training set:\")\n",
    "print(\"\\tA: {}, B: {}, C: {}\".format(num_A_train, num_B_train, num_C_train))\n",
    "print(\"Test set:\")\n",
    "print(\"\\tA: {}, B: {}, C: {}\".format(num_A_test, num_B_test, num_C_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe1708d-e3e6-41cd-8646-7961ab11483b",
   "metadata": {},
   "source": [
    "## One-hot encoding\n",
    "At the moment, we have category integer labels for each letter; for example, the labels for \"A,\" \"B,\" and \"C\" are encoded as 0, 1, and 2, respectively. But keep in mind that this format is not supported by Keras models, thus before feeding the labels to a Keras model, we need to one-hot encode them.<br>\n",
    "The one-dimensional label array will become a two-dimensional array as a result of this conversion.<br>\n",
    "<br>\n",
    "A distinct image is represented by each row in the two-dimensional array of one-hot encoded labels. The row has a 0 in other columns and a 1 in the column that matches the correct label.<br>\n",
    "As an example, the codes for 0 and 1 are [1, 0, 0], [0, 1, 0], and [0, 0, 1], respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f6742c-7271-48e2-97a1-820525fd62b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_OH=np_utils.to_categorical(y_train)\n",
    "y_test_OH=np_utils.to_categorical(y_test)\n",
    "model=Sequential()\n",
    "model.add(Conv2D(filters=5,kernel_size=5,padding='same',activation='relu',input_shape=(50,50,3)))\n",
    "model.add(MaxPooling2D(pool_size=4))\n",
    "model.add(Conv2D(filters=15,kernel_size=5,padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba444f4e-6e0e-4e24-99a7-e08cfe56914b",
   "metadata": {},
   "source": [
    "## Compiling the model\n",
    "\n",
    "After one-hot encoding the data, we can proceed with feeding it to the Keras model and compile the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240253c3-14f8-48aa-b918-4ebe685e7cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb6b15c-f687-41ee-b766-0b771fd93eaf",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "We fit the model to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad8eea7-e5fa-4a80-a4ab-70cdb7d4096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist=model.fit(x_train, y_train_OH,\n",
    "               validation_split=0.2,\n",
    "               epochs=2, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0eb75d6-64b2-4253-bd27-de7a4704a511",
   "metadata": {},
   "source": [
    "## Testing the model\n",
    "\n",
    "We will use the test dataset to evaluate the model. This will provide insight into the network's performance in categorizing previously unseen images!\n",
    "\n",
    "It is a positive indication that the model did not overfit to the training set if the test dataset's classification accuracy is comparable to that of the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6f3476-11de-44b5-863d-c623a9a9af3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "score=model.evaluate(x_test,y_test_OH,verbose=0)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7203fc6-9980-44d2-9455-31f5204b381b",
   "metadata": {},
   "source": [
    "## Visualizing mistakes\n",
    "On the test set, our network achieves really good accuracy.\n",
    "\n",
    "Reviewing the photographs can occasionally reveal unique features that the model finds puzzling. But it also frequently happens that it's difficult to understand what the model intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff3dccc-bd90-4abb-be56-bc4d77950160",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs = model.predict(x_test)\n",
    "y_preds = np.argmax(y_probs, axis=1)\n",
    "bad_test_idxs = np.where(y_preds != y_test)[0]\n",
    "fig=plt.figure(figsize=(25,4))\n",
    "for i, idx in enumerate(bad_test_idxs):\n",
    "    ax = fig.add_subplot(2, np.ceil(len(bad_test_idxs)/2), i+1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(x_test[idx]))\n",
    "    ax.set_title(\"{} (pred: {})\".format(labels[y_test[idx]], labels[y_preds[idx]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
